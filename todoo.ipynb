{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooo7QAf0un_K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToJ4zjhzi_hL"
      },
      "outputs": [],
      "source": [
        "train_data = '/content/dataset_directory/image_data/train/'\n",
        "val_data = '/content/dataset_directory/image_data/val/'\n",
        "test_data = '/content/dataset_directory/image_data/test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_eZaAhUOrJ6",
        "outputId": "19d52f1a-f43f-4e58-876d-ca7474b14faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3UjCRXCLJaq"
      },
      "outputs": [],
      "source": [
        "num_classes = 6\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 16\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Osfk0fiDjPmZ"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/mosquito_data.zip'\n",
        "extract_path = '/content/dataset_directory'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9pM5aH2qAsX",
        "outputId": "0fa47d91-e9f4-48ff-8b23-bbfc0ad76513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(img_width, img_height, 3),\n",
        "    include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94eqhJouMchO",
        "outputId": "327accb1-32b5-4693-9631-8d7822379a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu4IA1jBjdhH"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp5z68eOtcTK"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    samplewise_center=True,\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen_test = ImageDataGenerator(\n",
        "    samplewise_center=True,\n",
        "    rescale=1.0 / 255)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16baNEqvqhE4",
        "outputId": "6704aee6-cad9-40a5-824f-40dff9fa47d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1440 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYn3LBFfumAa",
        "outputId": "3a100f46-2fac-4561-dc0a-9912c3dbbb95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 150 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "val_generator = datagen.flow_from_directory(\n",
        "    val_data,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3sQ0MViroLo",
        "outputId": "52bd7c34-5b60-4a82-a8cd-49212ae24dc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 90 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "test_generator = datagen_test.flow_from_directory(\n",
        "    test_data,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtMwntFLeogf"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "# Separately from setting trainable on the model, we set training to False\n",
        "x = base_model(inputs, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUmd_3bLMYQk",
        "outputId": "914dbb6c-b3ed-4763-f6f5-b9aac5289986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14717766 (56.14 MB)\n",
            "Trainable params: 3078 (12.02 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEnql2KHNdU7"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDieCSU3OITg",
        "outputId": "9d77647e-9a10-4363-c8a4-73c485857d4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "58/90 [==================>...........] - ETA: 5:40 - loss: 1.7938 - accuracy: 0.1940"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOqmBIs_A978"
      },
      "outputs": [],
      "source": [
        "model.save('before_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TVqKq8dUvY-"
      },
      "outputs": [],
      "source": [
        "before_model = keras.models.load_model('before_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzgqsOjpVXVd"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AmAQZQ6VkXL"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHTZJIY9iMUe"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/after_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J34ed1Cc8-pm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yu-2xsw-k1sT"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_hjljVCnNCl"
      },
      "outputs": [],
      "source": [
        "after_model = keras.models.load_model('/content/drive/MyDrive/after_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnE1oeCP5sfs"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = after_model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTaVhE7vrwdy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "true_labels = []\n",
        "image_filenames = []\n",
        "\n",
        "for class_label in os.listdir(test_data):\n",
        "    class_dir = os.path.join(test_data, class_label)\n",
        "    if os.path.isdir(class_dir):\n",
        "        # 'class_label' contains the true label, and 'class_dir' is the directory for that class\n",
        "        for image_filename in os.listdir(class_dir):\n",
        "            if image_filename.endswith('.jpeg'):  # Adjust file extension as needed\n",
        "                true_labels.append(class_label)\n",
        "                image_filenames.append(os.path.join(class_label, image_filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImGJvx2UsMwP"
      },
      "outputs": [],
      "source": [
        "predicted_labels = after_model.predict(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN7yLJIT4aMH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predicted_labels = after_model.predict(test_generator)\n",
        "\n",
        "y_pred_labels = [y.argmax() for y in predicted_labels]\n",
        "\n",
        "y_true = test_generator.classes\n",
        "\n",
        "target_names = [\"Aedes aegypti\", \"Aedes albopictus\", \"Anopheles\", \"Culex\", \"Culiseta\", \"Aedes japonicus/Aedes koreicus\"]\n",
        "\n",
        "report = classification_report(y_true, y_pred_labels, target_names=target_names)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xhXvHiqszz7"
      },
      "outputs": [],
      "source": [
        "class_labels = sorted(set(true_labels))\n",
        "accuracies = []\n",
        "\n",
        "for i, label in enumerate(class_labels):\n",
        "    true_class = np.array(true_labels) == label\n",
        "    predicted_class_probabilities = predicted_labels[:, i]\n",
        "    predicted_class_labels = np.argmax(predicted_labels, axis=1)\n",
        "    predicted_class = predicted_class_labels == i\n",
        "    accuracy = np.mean(true_class == predicted_class)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "colors = ['#FFCA3A', '#ADB2D3', '#D16666', '#ACFCD9', '#7D84B2', '#F7C59F']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(class_labels, accuracies)\n",
        "for i in range(len(bars)):\n",
        "    bars[i].set_color(colors[i])\n",
        "    print(f'{class_labels[i]} : {accuracies[i]}')\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy for Each Class')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylim(0, 1)  # Set the y-axis limit to [0, 1] for accuracy values\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsuUJHal7PDX"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "\n",
        "source_path = 'after_model.h5'\n",
        "destination_path = '/content/drive/My Drive/'\n",
        "shutil.copy(source_path, destination_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMhQ-plJ84LN"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "def classify_new_image(model, image_path, class_labels):\n",
        "    # Load and preprocess the new image\n",
        "    img = image.load_img(image_path, target_size=(244, 244))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img / 255.0  # Rescale to match the training data preprocessing\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(img)\n",
        "\n",
        "    # Interpret predictions\n",
        "    class_indices = np.argmax(predictions, axis=1)\n",
        "    predicted_class = class_labels[class_indices[0]]\n",
        "\n",
        "    return predicted_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On6C0pAW9Exd"
      },
      "outputs": [],
      "source": [
        "#model = keras.models.load_model('your_model.h5')  # Load your saved model\n",
        "class_labels = [\"Aedes aegypti\", \"Aedes albopictus\", \"Anopheles\", \"Culex\", \"Culiseta\", \"Aedes japonicus/Aedes koreicus\"]\n",
        "image_path = '/content/dataset_directory/image_data/test/aegypti/aegypti_240.jpeg'  # Replace with the path to your new image\n",
        "\n",
        "predicted_class = classify_new_image(after_model, image_path, class_labels)\n",
        "\n",
        "print(f'The predicted class is: {predicted_class}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}